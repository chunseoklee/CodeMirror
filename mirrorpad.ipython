{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chunseoklee/CodeMirror/blob/master/mirrorpad.ipython\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NJ6LQ9L6UMCC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "###########tensorflow version:'1.13.0-dev20190215'##########\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow.contrib.slim as slim\n",
        "def generator(x, is_training=False, reuse=False):\n",
        "\n",
        "    with tf.variable_scope(\"generator\", reuse=reuse):\n",
        "        conv_layers= encoder(x)\n",
        "        network = decoder(conv_layers)\n",
        "\n",
        "    if is_training:\n",
        "        return network, conv_layers\n",
        "\n",
        "    return network\n",
        "\n",
        "def encoder(input_layer):\n",
        "    rgb = tf.identity(input_layer) #224\n",
        "    output_channel = 32\n",
        "    # rgb = pad_(rgb)\n",
        "    network0 = slim.conv2d(rgb,\n",
        "                          num_outputs=output_channel,\n",
        "                          kernel_size=[3, 3],\n",
        "                          stride=2,\n",
        "                          padding='SAME',# use 'same + no pad_' cost 0.7g Ram, but use 'valid + pad_' 5g Ram\n",
        "                          activation_fn=tf.nn.relu,\n",
        "                          biases_initializer=None)#112\n",
        "\n",
        "\n",
        "    network1 = block(network0, output_channel, 2, str='block1') #56\n",
        "    network2 = block(network1, output_channel, 1, str='block2')\n",
        "\n",
        "\n",
        "    network3 = block(network2, output_channel, 2, str='block3')#28\n",
        "    network4 = block(network3, output_channel, 1, str='block4')\n",
        "    network5 = block(network4, output_channel, 1, str='block5')\n",
        "\n",
        "    return network5\n",
        "\n",
        "\n",
        "def block(net, oup, stride, str):\n",
        "    assert stride in [1, 2]\n",
        "    with tf.variable_scope(str):\n",
        "        # net = pad_(net)\n",
        "        net = slim.separable_conv2d(net,\n",
        "                                    num_outputs=oup,\n",
        "                                    kernel_size=[3, 3],\n",
        "                                    depth_multiplier=1,\n",
        "                                    stride=stride,\n",
        "                                    padding='SAME',\n",
        "                                    activation_fn=tf.nn.relu,\n",
        "                                    biases_initializer=None)\n",
        "        return net\n",
        "\n",
        "\n",
        "\n",
        "# Decoder network\n",
        "def decoder(input_layer):\n",
        "    sb, sx, sy, sf = input_layer.get_shape().as_list()\n",
        "    network = upsample_layer(input_layer, sz=(sf, sf))\n",
        "\n",
        "    network = upsample_layer(network, sz=(sf, 32))\n",
        "\n",
        "    network = upsample_layer(network, sz=(32, 3))\n",
        "\n",
        "\n",
        "    return network\n",
        "\n",
        "# === Layers ==================================================================\n",
        "\n",
        "def upsample_layer(input_layer, sz):\n",
        "    height = input_layer.shape[1].value\n",
        "    width = input_layer.shape[2].value\n",
        "    net = tf.image.resize_images(input_layer, size=[height * 2, width * 2], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
        "    #net = pad_(net)\n",
        "    net = slim.conv2d(net,\n",
        "                    num_outputs=sz[1],\n",
        "                    kernel_size=[3, 3],\n",
        "                    stride=1,\n",
        "                    padding='SAME',\n",
        "                    activation_fn=tf.nn.relu,\n",
        "                    biases_initializer=None)\n",
        "\n",
        "    return net\n",
        "\n",
        "\n",
        "def pad_(input_tensor):\n",
        "    out = tf.identity(input_tensor)\n",
        "    out = tf.pad(out, paddings=[[0, 0], [1, 1], [1, 1], [0, 0]], mode='REFLECT')\n",
        "    return out\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rRKiVwPUTVh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "55f60f32-797c-4600-8fb4-18e24265113b"
      },
      "source": [
        "\n",
        "import tensorflow.contrib.slim as slim\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import sys\n",
        "#import network\n",
        "\n",
        "\n",
        "x = tf.placeholder(tf.float32, shape=[1, 1024, 768, 3], name='input')\n",
        "net= generator(x)\n",
        "\n",
        "sess = tf.InteractiveSession()\n",
        "sess.run(tf.global_variables_initializer())\n",
        "fake_data = np.ones(shape=(1, 1024, 768, 3), dtype=np.float32)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_session(sess, [x], [net])\n",
        "tflite_model = converter.convert()\n",
        "open(\"converted_model.tflite\", \"wb\").write(tflite_model)\n",
        "\n",
        "interpreter = tf.lite.Interpreter(model_path=\"converted_model.tflite\")\n",
        "interpreter.allocate_tensors()\n",
        "\n",
        "# Get input and output tensors.\n",
        "input_details = interpreter.get_input_details()\n",
        "output_details = interpreter.get_output_details()\n",
        "\n",
        "interpreter.set_tensor(input_details[0]['index'], fake_data)\n",
        "\n",
        "interpreter.invoke()\n",
        "y_predict = interpreter.get_tensor(output_details[0]['index'])\n",
        "\n",
        "\n",
        "sess.close()\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING: Logging before flag parsing goes to stderr.\n",
            "W0808 03:40:05.788565 140387379234688 deprecation.py:506] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
            "W0808 03:40:06.590068 140387379234688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/lite/python/util.py:238: convert_variables_to_constants (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.convert_variables_to_constants`\n",
            "W0808 03:40:06.591724 140387379234688 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/graph_util_impl.py:270: extract_sub_graph (from tensorflow.python.framework.graph_util_impl) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.compat.v1.graph_util.extract_sub_graph`\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}